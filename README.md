
---

# ğŸš€ FastLLM


FastLLM Ã© uma biblioteca Python com Ã«nfase em leveza e simplicidade de uso, com o objetivo de ajudar a desenvolver projetos baseados em LLMs (Large Language Models). Ele fornece uma interface simples para interagir com provedores compatÃ­veis com OpenAI, incluindo APIs de modelos open-source como Ollama e LM Studio.
O nome desta biblioteca foi inspirado no FastAPI, devido a sua sintaxe limpa e a facilidade de se prototipar uma nova API.

## ğŸŒŸ Funcionalidades

*   ğŸ’» Suporte a provedores compatÃ­veis com OpenAI: FastLLM se integra perfeitamente com APIs populares do OpenAI, permitindo que vocÃª aproveite o poder dos LLMs em seus aplicativos.
*   ğŸ”§ IntegraÃ§Ã£o fÃ¡cil: FastLLM fornece uma API Pythonica que torna fÃ¡cil incorporar a funcionalidade de LLM nos seus projetos.
*   ğŸ› ï¸ PersonalizaÃ§Ã£o: Com FastLLM, vocÃª pode adicionar facilmente ferramentas e funÃ§Ãµes (tool calling) personalizadas para estender as capacidades do seu aplicativo baseado em LLM. Utilizamos Pydantic para representar e validar inputs para as suas funÃ§Ãµes de forma simples e familiar.
*   ğŸ”„ Workflows: Crie e gerencie sequÃªncias de tarefas ou operaÃ§Ãµes, permitindo interaÃ§Ãµes e automaÃ§Ãµes complexas em seus aplicativos.

## ğŸ“¥ Primeiros passos

### ğŸ› ï¸ InstalaÃ§Ã£o

Para comeÃ§ar com FastLLM, instale a biblioteca usando pip:

```bash
python setup.py sdist bdist_wheel
pip install .
```

### ğŸ’¡ Uso

Aqui estÃ¡ um exemplo de como usar FastLLM em seu script Python:

```python
from fastllm import Agent, tool
from pydantic import BaseModel, Field


class SumRequest(BaseModel):
    num1: int = Field(..., description="O primeiro nÃºmero a ser adicionado")
    num2: int = Field(..., description="O segundo nÃºmero a ser adicionado")

@tool(
    description="Soma dois nÃºmeros e retorna o resultado",
    pydantic_model=SumRequest
)
def sum_numbers(inputs: SumRequest):
    print("ParÃ¢metros:", inputs.num1, "+", inputs.num2)
    return {"result": inputs.num1 + inputs.num2}

agent = Agent(
               model="qwen2.5:14b-instruct-q6_K",
               base_url="http://localhost:11434/v1",
               api_key="ollama",
               tools=[sum_numbers],
               system_prompt="VocÃª Ã© um assistente Ãºtil"
            )

for message in agent.generate("Calcular 1900 + 191"):
    print(message)
```

<p>VocÃª pode ver mais exemplos na pasta "examples" do repositÃ³rio! </p>

## ğŸ“„ LicenÃ§a

FastLLM Ã© liberado sob a LicenÃ§a MIT. Consulte o arquivo LICENSE para mais informaÃ§Ãµes.

## ğŸ’– Agradecimentos!

Esperamos que vocÃª encontre FastLLM Ãºtil em seus projetos baseados em LLM!

---

Let me know if you'd like any adjustments!